import asyncio
import functools
import re
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field, asdict
import json
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import akshare as ak
import pandas as pd

from src.utils.config_loader import ConfigLoader
from src.utils.logger import logger
from src.collector.sources.efinance_source import EfinanceSource
from src.collector.sources.akshare_source import AkshareSource
from src.collector.sources.tencent_source import TencentSource

from tenacity import retry, stop_after_attempt, wait_exponential


@dataclass
class CircuitBreakerState:
    """
    üîß ‰ºòÂåñÂêéÁöÑÁÜîÊñ≠Âô®Áä∂ÊÄÅ
    - Ë¶ÅÊ±ÇËøûÁª≠3Ê¨°Â§±Ë¥•ÊâçÁÜîÊñ≠
    - 30ÁßíÂêéËøõÂÖ•ÂçäÂºÄÁä∂ÊÄÅÔºåÂÖÅËÆ∏‰∏ÄÊ¨°Â∞ùËØï
    """
    failure_count: int = 0
    is_open: bool = False  # True = ÁÜîÊñ≠‰∏≠
    last_failure_time: float = 0.0

    # ÈÖçÁΩÆ
    FAILURE_THRESHOLD: int = 3  # ËøûÁª≠Â§±Ë¥•NÊ¨°ÊâçÁÜîÊñ≠
    RECOVERY_TIMEOUT: float = 30.0  # ÁÜîÊñ≠Âêé30ÁßíËøõÂÖ•ÂçäÂºÄÁä∂ÊÄÅ


class DataCollector:
    def __init__(self):
        # GitHub Actions runners / Standard Cloud Instances (2-4 vCPUs)
        self.executor = ThreadPoolExecutor(max_workers=16)
        self.config = ConfigLoader().config
        self.state_file = "data/circuit_breaker_state.json"

        # Priority: Tencent -> Efinance -> AkShare
        self.sources = [TencentSource(), EfinanceSource(), AkshareSource()]

        # Read history_days from config (needed for MACD calculation)
        risk_cfg = self.config.get('risk_management', {})
        ti_cfg = risk_cfg.get('technical_indicators', {})
        self.history_days = ti_cfg.get('history_days', 60)

        # üîß ‰ºòÂåñ: ‰ΩøÁî®ÁªìÊûÑÂåñÁöÑÁÜîÊñ≠Âô®Áä∂ÊÄÅÔºåÊõø‰ª£ÁÆÄÂçïÁöÑdisabled set
        self._circuit_breakers: Dict[str, CircuitBreakerState] = {
            source.get_source_name(): CircuitBreakerState()
            for source in self.sources
        }
        self._load_circuit_breaker_state()

    def _load_circuit_breaker_state(self):
        """Load circuit breaker states from disk."""
        try:
            import os
            if os.path.exists(self.state_file):
                with open(self.state_file, 'r') as f:
                    data = json.load(f)
                    for name, state_dict in data.items():
                        if name in self._circuit_breakers:
                            # Restore state
                            cb = self._circuit_breakers[name]
                            cb.failure_count = state_dict.get('failure_count', 0)
                            cb.is_open = state_dict.get('is_open', False)
                            cb.last_failure_time = state_dict.get('last_failure_time', 0.0)
                logger.info("Circuit breaker states loaded from disk.")
        except Exception as e:
            logger.warning(f"Failed to load circuit breaker states: {e}")

    def _save_circuit_breaker_state(self):
        """Persist circuit breaker states to disk."""
        try:
            states = {name: asdict(cb) for name, cb in self._circuit_breakers.items()}
            with open(self.state_file, 'w') as f:
                json.dump(states, f)
        except Exception as e:
            logger.warning(f"Failed to save circuit breaker states: {e}")

    def _should_skip_source(self, source_name: str) -> bool:
        """
        Ê£ÄÊü•Êï∞ÊçÆÊ∫êÊòØÂê¶Â∫îËØ•Ë∑≥ËøáÔºàÁÜîÊñ≠‰∏≠‰∏îÊú™Âà∞ÊÅ¢Â§çÊó∂Èó¥Ôºâ
        """
        cb = self._circuit_breakers.get(source_name)
        if not cb:
            return False

        if not cb.is_open:
            return False

        # Ê£ÄÊü•ÊòØÂê¶Âà∞‰∫ÜÂçäÂºÄÊÅ¢Â§çÊó∂Èó¥
        elapsed = time.time() - cb.last_failure_time
        if elapsed >= cb.RECOVERY_TIMEOUT:
            logger.info(f"Circuit Breaker: {source_name} entering half-open state (trying recovery)")
            return False  # ÂÖÅËÆ∏Â∞ùËØï

        return True  # ‰ªçÂú®ÁÜîÊñ≠‰∏≠

    def _record_success(self, source_name: str):
        """ËÆ∞ÂΩïÊàêÂäüÔºåÈáçÁΩÆÁÜîÊñ≠Âô®"""
        cb = self._circuit_breakers.get(source_name)
        if cb:
            if cb.is_open:
                logger.info(f"Circuit Breaker: {source_name} recovered successfully")
            cb.failure_count = 0
            cb.is_open = False
            self._save_circuit_breaker_state()

    def _record_failure(self, source_name: str):
        """ËÆ∞ÂΩïÂ§±Ë¥•ÔºåÂèØËÉΩËß¶ÂèëÁÜîÊñ≠"""
        cb = self._circuit_breakers.get(source_name)
        if not cb:
            return

        cb.failure_count += 1
        cb.last_failure_time = time.time()

        if cb.failure_count >= cb.FAILURE_THRESHOLD:
            cb.is_open = True
            logger.warning(
                f"Circuit Breaker: {source_name} OPEN after {cb.failure_count} consecutive failures. "
                f"Will retry in {cb.RECOVERY_TIMEOUT}s."
            )
        else:
            logger.info(
                f"Circuit Breaker: {source_name} failure {cb.failure_count}/{cb.FAILURE_THRESHOLD}"
            )
        self._save_circuit_breaker_state()

    async def _run_blocking(self, func, *args, **kwargs):
        """
        Helper to run blocking calls in a thread executor with smart retry logic and timeout.
        """
        loop = asyncio.get_running_loop()
        timeout = kwargs.pop('timeout', 5) # Default 5s timeout (Fail Fast)
        
        @retry(
            stop=stop_after_attempt(3), 
            wait=wait_exponential(multiplier=1, min=1, max=10),
            reraise=True
        )
        def retriable_func():
            try:
                return func(*args, **kwargs)
            except Exception as e:
                logger.warning(f"API Call {func.__name__} failed: {e}. Retrying...")
                raise e

        try:
            return await asyncio.wait_for(
                loop.run_in_executor(self.executor, retriable_func),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            logger.error(f"Command {func.__name__} timed out after {timeout}s.")
            raise
        except Exception as e:
            # logger.error(f"Command {func.__name__} failed definitively after retries.")
            raise e

    async def _fetch_with_fallback(self, method_name: str, *args, **kwargs) -> Any:
        """
        Try to fetch data from sources in priority order.
        üîß ‰ºòÂåñ: ‰ΩøÁî®ÊîπËøõÁöÑÁÜîÊñ≠Âô®ÈÄªËæë
        """
        last_exception = None
        for source in self.sources:
            source_name = source.get_source_name()

            # ÁÜîÊñ≠Âô®Ê£ÄÊü•
            if self._should_skip_source(source_name):
                continue

            try:
                func = getattr(source, method_name)
                # Run sync source method in thread pool
                result = await self._run_blocking(func, *args, **kwargs)

                # Check for validity
                if result is not None:
                    if isinstance(result, pd.DataFrame) and result.empty:
                        continue  # Try next source if Empty DataFrame
                    # ÊàêÂäüÔºÅÈáçÁΩÆÁÜîÊñ≠Âô®
                    self._record_success(source_name)
                    return result
            except Exception as e:
                logger.warning(f"Source {source_name} failed for {method_name}: {e}")
                # ËÆ∞ÂΩïÂ§±Ë¥•ÔºàÂèØËÉΩËß¶ÂèëÁÜîÊñ≠Ôºâ
                self._record_failure(source_name)
                last_exception = e
                continue

        logger.error(f"All sources failed for {method_name}.")
        return None

    def _get_dynamic_start_date(self, days_lookback: int = 60) -> str:
        return (datetime.now() - timedelta(days=days_lookback)).strftime("%Y%m%d")

    async def get_market_breadth(self) -> str:
        """
        Fetches market breadth (Rise/Fall ratio).
        """
        logger.info("Fetching market breadth...")
        # Try abstraction first, or fallback to current manual logic if needed?
        # Current logic is specific with 'stock_zh_a_spot_em'.
        # Let's rely on AkShareSource's fetch_market_breadth for simplicity?
        # But wait, AkshareSource's impl was a placeholder that returns string.
        # The original logic calculated it from spot data.
        # Let's stick to using fetch_market_breadth from interfaces.
        res = await self._fetch_with_fallback('fetch_market_breadth')
        return res if res else "Unknown"

    async def get_north_funds(self) -> float:
        """
        Fetches Real-time Northbound Fund Net Inflow (Unit: 100 million).
        Kept specific to AkShare for now as it's specialized.
        """
        logger.info("Fetching Northbound funds...")
        try:
            df = await self._run_blocking(ak.stock_hsgt_fund_flow_summary_em)
            if df is None or df.empty:
                return 0.0

            mask = df.astype(str).apply(lambda x: x.str.contains('ÂåóÂêë')).any(axis=1)
            north_rows = df[mask]
            
            if north_rows.empty:
                return 0.0
            
            # Heuristic to find value column
            value_col = next((col for col in df.columns if 'ÂáÄÊµÅÂÖ•' in str(col)), None)
            
            if not value_col:
                raw_val = north_rows.iloc[0, 1]
            else:
                raw_val = north_rows.iloc[0][value_col]

            val_str = str(raw_val)
            val_clean = re.sub(r'[^\d\.\-]', '', val_str)
            
            try:
                return round(float(val_clean), 2)
            except ValueError:
                return 0.0

        except Exception as e:
            logger.error(f"Error fetching North funds: {e}")
            return 0.0

    async def get_indices(self) -> Dict[str, Dict]:
        """
        Fetches major indices.
        """
        try:
             df = await self._run_blocking(ak.stock_zh_index_spot_sina)
             target_map = {
                 "‰∏äËØÅÊåáÊï∞": "sh000001",
                 "Ê∑±ËØÅÊàêÊåá": "sz399001", 
                 "Âàõ‰∏öÊùøÊåá": "sz399006"
             }
             results = {}
             for name in target_map.keys():
                 row = df[df['ÂêçÁß∞'] == name]
                 if not row.empty:
                     try:
                         results[name] = {
                             "current": float(row.iloc[0]['ÊúÄÊñ∞‰ª∑']),
                             "change_pct": float(row.iloc[0]['Ê∂®Ë∑åÂπÖ'])
                         }
                     except (ValueError, KeyError):
                         continue
             return results
        except Exception as e:
            logger.error(f"Failed to fetch indices: {e}")
            return {}

    async def get_macro_news(self) -> Dict[str, List[str]]:
        """
        Fetches macro news.
        """
        logger.info("Fetching macro news...")
        result: Dict[str, List[str]] = {"telegraph": [], "ai_tech": []}
        
        try:
            today_str = datetime.now().strftime('%Y%m%d')
            df_news = await self._run_blocking(ak.news_cctv, date=today_str)
            
            if df_news is None or df_news.empty:
                 yesterday_str = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
                 df_news = await self._run_blocking(ak.news_cctv, date=yesterday_str)

            if df_news is not None and not df_news.empty:
                result["telegraph"] = df_news.head(10)['title'].tolist()
            else:
                df_global = await self._run_blocking(ak.stock_info_global_em)
                if df_global is not None and not df_global.empty:
                    result["telegraph"] = df_global.head(10)['Ê†áÈ¢ò'].tolist()

        except Exception as e:
            logger.warning(f"Failed to fetch macro news: {e}")
        
        ai_keywords = ['‰∫∫Â∑•Êô∫ËÉΩ', 'AI', 'ËäØÁâá', 'ÂçäÂØº‰Ωì', 'ÁÆóÂäõ', 'Â§ßÊ®°Âûã', 'GPU', 'Ëã±‰ºüËææ', 'Âçé‰∏∫', 'ÁßëÊäÄ', 'Êú∫Âô®']
        if result["telegraph"]:
            result["ai_tech"] = [
                n for n in result["telegraph"] 
                if any(k in n for k in ai_keywords)
            ][:5]
        
        return result

    async def collect_all(self, portfolio: List[Dict]):
        """
        Main entry point. Orchestrates parallel data fetching.
        """
        logger.info("Starting Batch Data Collection (Dual Source)...")
        
        global_tasks = [
            self.get_market_breadth(),
            self.get_north_funds(),
            self.get_indices(),
            self.get_macro_news()
        ]
        
        # 2. Fetch Spot Data via Fallback
        # This will try Efinance first, then AkShare
        df_all_spot = await self._fetch_with_fallback('fetch_spot_data')
        if df_all_spot is None:
            df_all_spot = pd.DataFrame()
            logger.warning("All sources failed to fetch bulk spot data. Will rely on individual fetch.")
        
        stock_tasks = []
        for stock in portfolio:
            code = stock['code']
            stock_tasks.append(self._fetch_individual_stock_extras(code, stock.get('name', 'Unknown'), df_all_spot))
            
        try:
            global_results = await asyncio.gather(*global_tasks, return_exceptions=True)
            stock_results = await asyncio.gather(*stock_tasks, return_exceptions=True)
        except Exception as e:
            logger.error(f"Critical error during gather: {e}")
            # Try to salvage whatever we have
            global_results = [None] * 4
            stock_results = []

        market_breadth = global_results[0] if global_results and not isinstance(global_results[0], Exception) else "Error"
        north_funds = global_results[1] if global_results and not isinstance(global_results[1], Exception) else 0.0
        indices = global_results[2] if global_results and not isinstance(global_results[2], Exception) else {}
        macro_news = global_results[3] if global_results and not isinstance(global_results[3], Exception) else {"telegraph": [], "ai_tech": []}
        
        valid_stocks = []
        if stock_results:
            valid_stocks = [res for res in stock_results if not isinstance(res, Exception) and isinstance(res, dict) and "error" not in res]

        return {
            "market_breadth": market_breadth,
            "north_funds": north_funds,
            "indices": indices,
            "macro_news": macro_news,
            "stocks": valid_stocks
        }

    # ============================================================
    # Morning Mode: ÁõòÂâçÂ§ñÁõòÊï∞ÊçÆÈááÈõÜ
    # ============================================================

    async def get_global_indices(self) -> List[Dict]:
        """
        Ëé∑ÂèñÈöîÂ§úÂÖ®ÁêÉÊåáÊï∞ÔºàÁæéËÇ°/ÊÅíÁîü/ÁæéÂÖÉÊåáÊï∞Á≠âÔºâ„ÄÇ
        Uses ak.index_global_spot_em()
        """
        logger.info("Fetching global indices...")
        try:
            df = await self._run_blocking(ak.index_global_spot_em, timeout=20)
            if df is None or df.empty:
                return []

            targets = ['Ê†áÊôÆ500', 'Á∫≥ÊñØËææÂÖã', 'ÈÅìÁêºÊñØ', 'ÊÅíÁîüÊåáÊï∞', 'ÁæéÂÖÉÊåáÊï∞',
                        'Á∫≥ÊñØËææÂÖã100', 'Êó•Áªè225']
            results = []
            for name in targets:
                row = df[df['ÂêçÁß∞'].str.contains(name, na=False)]
                if not row.empty:
                    try:
                        results.append({
                            "name": name,
                            "current": float(row.iloc[0].get('ÊúÄÊñ∞‰ª∑', 0)),
                            "change_pct": float(row.iloc[0].get('Ê∂®Ë∑åÂπÖ', 0)),
                            "change_amount": float(row.iloc[0].get('Ê∂®Ë∑åÈ¢ù', 0)),
                        })
                    except (ValueError, KeyError):
                        continue
            return results
        except Exception as e:
            logger.error(f"Failed to fetch global indices: {e}")
            return []

    async def get_commodity_futures(self) -> List[Dict]:
        """
        Ëé∑ÂèñÈöîÂ§úÂ§ßÂÆóÂïÜÂìÅÊúüË¥ßÔºàÈªÑÈáë/ÁôΩÈì∂/Èìú/ÂéüÊ≤πÔºâ„ÄÇ
        Uses ak.futures_global_spot_em()
        """
        logger.info("Fetching commodity futures...")
        try:
            df = await self._run_blocking(ak.futures_global_spot_em, timeout=20)
            if df is None or df.empty:
                return []

            targets = ['ÈªÑÈáë', 'ÁôΩÈì∂', 'Èìú', 'WTIÂéüÊ≤π', 'Â∏É‰º¶ÁâπÂéüÊ≤π', 'COMEXÈìú']
            results = []
            for name in targets:
                row = df[df['ÂêçÁß∞'].str.contains(name, na=False)]
                if not row.empty:
                    try:
                        results.append({
                            "name": row.iloc[0].get('ÂêçÁß∞', name),
                            "current": float(row.iloc[0].get('ÊúÄÊñ∞‰ª∑', 0)),
                            "change_pct": float(row.iloc[0].get('Ê∂®Ë∑åÂπÖ', 0)),
                        })
                    except (ValueError, KeyError):
                        continue
            return results
        except Exception as e:
            logger.error(f"Failed to fetch commodity futures: {e}")
            return []

    async def get_us_treasury_yields(self) -> Dict:
        """
        Ëé∑ÂèñÁæéÂÄ∫Êî∂ÁõäÁéáÔºà2Y/10Y/Âà©Â∑ÆÔºâ„ÄÇ
        Uses ak.bond_zh_us_rate() with pandas date filtering.
        """
        logger.info("Fetching US treasury yields...")
        try:
            df = await self._run_blocking(ak.bond_zh_us_rate, start_date="2024-01-01", timeout=20)
            if df is None or df.empty:
                return {}

            # Get most recent row
            latest = df.iloc[-1]
            yield_2y = float(latest.get('ÁæéÂõΩÂõΩÂÄ∫Êî∂ÁõäÁéá2Âπ¥', 0))
            yield_10y = float(latest.get('ÁæéÂõΩÂõΩÂÄ∫Êî∂ÁõäÁéá10Âπ¥', 0))
            spread = round(yield_10y - yield_2y, 4)

            result = {
                "yield_2y": yield_2y,
                "yield_10y": yield_10y,
                "spread_10y_2y": spread,
            }

            # Calculate change if we have at least 2 rows
            if len(df) >= 2:
                prev = df.iloc[-2]
                prev_10y = float(prev.get('ÁæéÂõΩÂõΩÂÄ∫Êî∂ÁõäÁéá10Âπ¥', 0))
                result["yield_10y_change"] = round(yield_10y - prev_10y, 4)

            return result
        except Exception as e:
            logger.error(f"Failed to fetch US treasury yields: {e}")
            return {}

    async def _fetch_morning_stock_context(self, code: str, name: str) -> Dict:
        """
        Ëé∑ÂèñÊåÅ‰ªìËÇ°Á•®ÁöÑÁõòÂâç‰∏ä‰∏ãÊñáÔºàÊò®Êó•Êî∂Áõò‰ª∑ + MA20ÔºåÊó†ÂÆûÊó∂‰ª∑Ôºâ„ÄÇ
        """
        try:
            df_hist = await self._fetch_with_fallback('fetch_prices', code=code, count=self.history_days)
            if df_hist is None or df_hist.empty:
                return {"code": code, "name": name, "error": "no_history"}

            # Determine close column
            if 'close' in df_hist.columns:
                close_col = 'close'
            elif 'Êî∂Áõò' in df_hist.columns:
                close_col = 'Êî∂Áõò'
            elif 'Close' in df_hist.columns:
                close_col = 'Close'
            else:
                return {"code": code, "name": name, "error": "no_close_column"}

            last_close = float(df_hist.iloc[-1][close_col])

            # Calculate MA20 from pure historical closes (no real-time stitching)
            ma_window = self.config.get('risk_management', {}).get('ma_window', 20)
            closes = df_hist[close_col].tail(ma_window).tolist()
            ma20 = sum(closes) / len(closes) if closes else 0.0
            bias_pct = (last_close - ma20) / ma20 if ma20 > 0 else 0.0

            # Determine MA20 status
            if bias_pct > 0.01:
                ma20_status = "ABOVE"
            elif bias_pct < -0.01:
                ma20_status = "BELOW"
            else:
                ma20_status = "NEAR"

            return {
                "code": code,
                "name": name,
                "last_close": round(last_close, 3),
                "ma20": round(ma20, 3),
                "bias_pct": round(bias_pct, 4),
                "ma20_status": ma20_status,
            }
        except Exception as e:
            logger.error(f"Failed to fetch morning context for {code}: {e}")
            return {"code": code, "name": name, "error": str(e)}

    async def collect_morning_data(self, portfolio: List[Dict]) -> Dict[str, Any]:
        """
        Êó©Êä•Ê®°ÂºèÁöÑ‰∏ªÂÖ•Âè£„ÄÇÂπ∂Ë°åÈááÈõÜÂ§ñÁõòÊï∞ÊçÆ + Êò®Êó•ÊåÅ‰ªì‰∏ä‰∏ãÊñá„ÄÇ
        """
        logger.info("Starting Morning Pre-Market Data Collection...")

        # Global overnight data tasks
        global_tasks = [
            self.get_global_indices(),
            self.get_commodity_futures(),
            self.get_us_treasury_yields(),
            self.get_macro_news(),
        ]

        # Per-stock historical context
        stock_tasks = [
            self._fetch_morning_stock_context(s['code'], s.get('name', 'Unknown'))
            for s in portfolio
        ]

        try:
            all_results = await asyncio.gather(*global_tasks, *stock_tasks, return_exceptions=True)
            global_results = all_results[:4]
            stock_results = all_results[4:]
        except Exception as e:
            logger.error(f"Critical error during morning gather: {e}")
            global_results = [None] * 4
            stock_results = []

        global_indices = global_results[0] if not isinstance(global_results[0], Exception) else []
        commodities = global_results[1] if not isinstance(global_results[1], Exception) else []
        us_treasury = global_results[2] if not isinstance(global_results[2], Exception) else {}
        macro_news = global_results[3] if not isinstance(global_results[3], Exception) else {"telegraph": [], "ai_tech": []}

        # Log failures for debugging
        labels = ['global_indices', 'commodities', 'us_treasury', 'macro_news']
        for i, label in enumerate(labels):
            if isinstance(global_results[i], Exception):
                logger.warning(f"Morning data {label} failed: {global_results[i]}")

        valid_stocks = [
            res for res in stock_results
            if not isinstance(res, Exception) and isinstance(res, dict) and "error" not in res
        ]

        return {
            "global_indices": global_indices,
            "commodities": commodities,
            "us_treasury": us_treasury,
            "macro_news": macro_news,
            "stocks": valid_stocks,
        }

    async def _fetch_individual_stock_extras(self, code: str, stock_name: str, df_all_spot: pd.DataFrame) -> Dict:
        """
        Fetches History and News for a specific stock using fallback.
        """
        try:
            # 1. Spot Data logic
            current_price = 0.0
            pct_change = 0.0
            volume = 0.0
            turnover_rate = 0.0
            name = stock_name

            if not df_all_spot.empty:
                spot_row = df_all_spot[df_all_spot['code'] == code]
                if not spot_row.empty:
                    try:
                        current_price = float(spot_row.iloc[0]['current_price'])
                        pct_change = float(spot_row.iloc[0]['pct_change'])
                        volume = float(spot_row.iloc[0].get('volume', 0))
                        turnover_rate = float(spot_row.iloc[0].get('turnover_rate', 0))
                    except (ValueError, KeyError, IndexError):
                        pass

            # 2. Try Individual Real-Time Quote (Fallback for Spot)
            # This is critical if bulk spot fetch failed (e.g. Efinance timeout)
            if current_price == 0.0:
                quote = await self._fetch_with_fallback('fetch_single_quote', code=code)
                if quote:
                    try:
                        current_price = float(quote['current_price'])
                        pct_change = float(quote['pct_change'])
                        volume = float(quote.get('volume', 0))
                        turnover_rate = float(quote.get('turnover_rate', 0))
                    except Exception as e:
                        logger.warning(f"Failed to parse quote for {code}: {e}")

            # 3. Fetch Prices (History) via Fallback
            df_hist = await self._fetch_with_fallback('fetch_prices', code=code, count=self.history_days)
            if df_hist is None:
                df_hist = pd.DataFrame()
                logger.warning(f"History fetch failed for {code}")

            # Calculate 5-day average volume from history for volume ratio
            # üîß ‰øÆÂ§ç: ÊéíÈô§‰ªäÊó•Êï∞ÊçÆÔºåÁ°Æ‰øù5Êó•ÂùáÈáèËÆ°ÁÆóÂáÜÁ°Æ
            avg_volume_5d = 0.0
            if not df_hist.empty:
                # Fallback for current_price if spot failed
                if current_price == 0.0:
                    try:
                        current_price = float(df_hist.iloc[-1]['close'])
                        if len(df_hist) >= 2:
                            prev_close = float(df_hist.iloc[-2]['close'])
                            if prev_close > 0:
                                pct_change = ((current_price - prev_close) / prev_close) * 100
                    except Exception:
                        pass

                # üîß ‰øÆÂ§ç: ËøáÊª§‰ªäÊó•Êï∞ÊçÆÂêéËÆ°ÁÆó5Êó•ÂùáÈáè
                # ÈóÆÈ¢ò: df_histÂèØËÉΩÂåÖÂê´‰ªäÊó•ÂçäÂ§©Êï∞ÊçÆÔºåÂØºËá¥ÂùáÈáèË¢´Êãâ‰Ωé
                # Ëß£ÂÜ≥: Áªü‰∏Ä‰ΩøÁî®Êó•ÊúüÂà§Êñ≠
                if 'volume' in df_hist.columns and len(df_hist) >= 5:
                    try:
                        # Â∞ùËØïÊåâÊó•ÊúüËøáÊª§
                        today = datetime.now().date()
                        if 'date' in df_hist.columns:
                            df_hist_copy = df_hist.copy()
                            df_hist_copy['date'] = pd.to_datetime(df_hist_copy['date'])
                            df_past = df_hist_copy[df_hist_copy['date'].dt.date < today]
                        elif 'Êó•Êúü' in df_hist.columns:
                            df_hist_copy = df_hist.copy()
                            df_hist_copy['Êó•Êúü'] = pd.to_datetime(df_hist_copy['Êó•Êúü'])
                            df_past = df_hist_copy[df_hist_copy['Êó•Êúü'].dt.date < today]
                        else:
                            # Êó†Êó•ÊúüÂàóÔºåÂ¶ÇÊûúÊï∞ÊçÆË∂≥Â§üÂ§öÔºå‰øùÂÆàÂàáÊéâÊúÄÂêé‰∏ÄË°å
                            if len(df_hist) >= 6:
                                df_past = df_hist.iloc[:-1]
                            else:
                                df_past = df_hist # Âè™ËÉΩÁ°¨ÁùÄÂ§¥ÁöÆÁî®‰∫Ü
                        
                        if len(df_past) >= 5:
                            avg_volume_5d = float(df_past.tail(5)['volume'].mean())
                        elif len(df_past) > 0:
                            # Ëá≥Â∞ëÊúâ‰∏Ä‰∫õÊï∞ÊçÆ
                            avg_volume_5d = float(df_past['volume'].mean())
                        else:
                             avg_volume_5d = 0.0

                    except Exception as e:
                        logger.warning(f"Failed to calculate avg_volume_5d for {code}: {e}")
                        # ÈôçÁ∫ßÂà∞ÂéüÈÄªËæë
                        if len(df_hist) >= 6:
                             avg_volume_5d = float(df_hist.tail(6).head(5)['volume'].mean())
                        else:
                             avg_volume_5d = float(df_hist['volume'].mean())

                df_hist = df_hist.tail(self.history_days)
            
            # 3. Fetch News via Fallback
            news_str = await self._fetch_with_fallback('fetch_news', code=code, count=5)
            # news_str returns string separated by ;
            news_list = news_str.split("; ") if news_str else []

            return {
                "code": code,
                "name": name,
                "current_price": current_price,
                "pct_change": pct_change,
                "volume": volume,
                "turnover_rate": turnover_rate,
                "avg_volume_5d": avg_volume_5d,
                "history": df_hist,
                "news": news_list
            }
            
        except Exception as e:
            logger.error(f"Failed individual fetch for {code}: {e}")
            return {"code": code, "error": str(e)}

if __name__ == "__main__":
    # Smoke Test
    class MockConfig:
        config = {'portfolio': [{'code': '600519', 'name': 'ËåÖÂè∞'}]}
    
    start_t = datetime.now()
    collector = DataCollector()
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    result = loop.run_until_complete(collector.collect_all(MockConfig.config['portfolio']))
    
    print(f"Time taken: {datetime.now() - start_t}")
    print(f"Market Breadth: {result['market_breadth']}")
    print(f"North Funds: {result['north_funds']}")
    if result['stocks']:
        print(f"Sample Stock Price: {result['stocks'][0]['current_price']}")
        print(f"Sample Hist Shape: {result['stocks'][0]['history'].shape}")
